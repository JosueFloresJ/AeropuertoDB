{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79885a4b",
   "metadata": {},
   "source": [
    "# Web Scraping para la Recopilación de Datos de Aeropuertos en América\n",
    "\n",
    "## Introducción:\n",
    "\n",
    "Este Jupyter Notebook tiene como objetivo principal la recopilación de datos de aeropuertos en América mediante técnicas de web scraping. En el contexto de nuestro proyecto de base de datos orientada a grafos para la gestión de aeropuertos, es esencial contar con información actualizada y precisa sobre los aeropuertos en la región.\n",
    "\n",
    "El web scraping nos permitirá extraer datos relevantes de fuentes en línea, como sitios web de autoridades de aviación y aerolíneas. Estos datos incluirán detalles sobre ubicaciones geográficas, nombres de aeropuertos, servicios disponibles, rutas operadas y otros atributos esenciales.\n",
    "\n",
    "## Objetivos:\n",
    "\n",
    "Obtener datos de aeropuertos en América a partir de fuentes en línea.\n",
    "Extraer información clave, como nombres de aeropuertos, ubicaciones y detalles operativos.\n",
    "Almacenar los datos recopilados en un formato adecuado para su posterior análisis y uso en nuestra base de datos orientada a grafos.\n",
    "\n",
    "### Autor\n",
    "\n",
    "Este Python Notebook está hecho por **Manrique Camacho P. (C01554)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364df272",
   "metadata": {},
   "source": [
    "## Importación de librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ab0a4",
   "metadata": {},
   "source": [
    "* **Requests**: La biblioteca requests le permite al usuario realizar solicitudes HTTP a las páginas web que desee analizar, facilitando la descarga del contenido HTML de dichas páginas para su posterior procesamiento.\n",
    "\n",
    "* **Beautiful Soup (bs4)**: Beautiful Soup es una herramienta útil para analizar y buscar elementos HTML en el contenido descargado. Permite al usuario buscar y extraer información específica de las páginas web, como títulos, párrafos, enlaces y más.\n",
    "\n",
    "* **Selenium**: Cuando los sitios web utilizan JavaScript para cargar contenido dinámico, selenium se convierte en una opción valiosa. Con esta biblioteca, el usuario puede automatizar un navegador web para interactuar con el sitio web y extraer datos de páginas que requieren interacción.\n",
    "\n",
    "* **Pandas**: Pandas es una biblioteca esencial para estructurar y manipular los datos extraídos. Permite al usuario crear DataFrames para organizar los datos en filas y columnas, lo que facilita las operaciones de limpieza, filtrado y procesamiento.\n",
    "\n",
    "* **Matplotlib y Seaborn**: Estas bibliotecas son útiles para crear gráficos y visualizaciones si se desea presentar los datos recopilados de manera visual. Permiten personalizar gráficos para mostrar tendencias o patrones en los datos.\n",
    "\n",
    "* **GeoPandas**: Si el proyecto involucra datos geoespaciales o la representación geográfica de aeropuertos, GeoPandas es una herramienta útil. Permite al usuario trabajar con datos geoespaciales, crear mapas y realizar análisis geoespaciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2016cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import ui\n",
    "import chromedriver_autoinstaller\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a18a75",
   "metadata": {},
   "source": [
    "## Web Scraping para Recopilación de Datos\n",
    "\n",
    "En esta sección, se explorará el web scraping, una técnica automatizada para obtener datos de sitios web. Los temas clave incluyen:\n",
    "\n",
    "* **Solicitudes HTTP**: Se utilizará la biblioteca requests para descargar el contenido HTML de las páginas web.\n",
    "* **Análisis HTML**: Se empleará Selenium para interactuar con sitios web dinámicos y extraer información relevante.\n",
    "* **Recopilación de Datos**: Se llevará a cabo la recolección de datos desde los sitios web seleccionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ca86baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_autoinstaller.install()  # Instala automáticamente la versión correcta de ChromeDriver\n",
    "ae_centralamerica = ['pty/airport-panama-city-tocumen','sjo/airport-san-jose-juan-santamaria',\n",
    "                    'sal/airport-san-salvador-cuscatlan','mga/airport-managua',\n",
    "                    'tgu/airport-tegucigalpa'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b9fd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "res = requests.get(\"https://airportinfo.live/arrivals/sjo/airport-san-jose-juan-santamaria\",headers ={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "soup = bs4.BeautifulSoup(res.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49006e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def airport_basic(extension): #Nos dara la información general del aeropuerto\n",
    "\n",
    "    res = requests.get(f\"https://airportinfo.live/arrivals/{extension}\",headers ={'User-Agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    nombre = soup.find_all('strong')[-1].get_text(strip=True)\n",
    "    telephone = ' '.join(soup.find_all('li')[-3].text.split()[2:])\n",
    "    timezone = ' '.join(soup.find_all('li')[-2].text.split()[5:])\n",
    "\n",
    "    data = []\n",
    "    for i in soup.find_all('li')[-4]:\n",
    "        data.append(i)\n",
    "    \n",
    "    location = data[2]\n",
    "    \n",
    "    info_ae = [nombre, location, timezone, telephone]\n",
    "    \n",
    "    return info_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "45fbc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://airportinfo.live/arrivals/sjo/airport-san-jose-juan-santamaria\")\n",
    "hora = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"timeStart\"]')))\n",
    "driver.execute_script(\"return arguments[0].scrollIntoView(true);\", hora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "177c3384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Salvador [SAL]\n"
     ]
    }
   ],
   "source": [
    "pais = driver.find_element(By.XPATH, '//*[@id=\"AV627\"]/td[2]/a')\n",
    "print(pais.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "64850b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AV 627', 'San Salvador [SAL]', 'Avianca 21:50', '[Oct-8]', '', '', '23:05', '23:00', 'TM', 'ARRIVED', 'AC 6137', 'San Salvador [SAL]', 'Air Canada 21:50', '[Oct-8]', '', '', '23:05', '23:00', 'TM', 'ARRIVED', 'Codeshare Flight - operated by AV627', 'IB 7803', 'San Salvador [SAL]', 'Iberia 21:50', '[Oct-8]', '', '', '23:05', '23:00', 'TM', 'ARRIVED', 'Codeshare Flight - operated by AV627', 'AV 651', 'Guatemala City [GUA]', 'Avianca 21:30', '[Oct-8]', '', '', '23:05', '22:56', 'TM', 'ARRIVED', 'AC 6122', 'Guatemala City [GUA]', '21:30', '[Oct-8]', '', '', '23:05', '22:56', 'TM', 'ARRIVED', 'Codeshare Flight - operated by AV651', 'AS 1390', 'Los Angeles [LAX]', 'Alaska Airlines 16:53', '17:40', '[Oct-8]', 'T664A', '23:44', '23:59', 'TMHG', 'IN AIR']\n"
     ]
    }
   ],
   "source": [
    "body = driver.find_element(By.XPATH, '//*[@id=\"San José-arrivals\"]/tbody')\n",
    "print(body.text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ede36746",
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: stale element not found\n  (Session info: chrome=117.0.5938.149)\nStacktrace:\n0   chromedriver                        0x0000000100b4ad68 chromedriver + 4337000\n1   chromedriver                        0x0000000100b42de4 chromedriver + 4304356\n2   chromedriver                        0x000000010076fa5c chromedriver + 293468\n3   chromedriver                        0x0000000100774cc8 chromedriver + 314568\n4   chromedriver                        0x00000001007768dc chromedriver + 321756\n5   chromedriver                        0x0000000100776a08 chromedriver + 322056\n6   chromedriver                        0x00000001007af3d4 chromedriver + 553940\n7   chromedriver                        0x00000001007aa200 chromedriver + 532992\n8   chromedriver                        0x00000001007ef908 chromedriver + 817416\n9   chromedriver                        0x00000001007a8a5c chromedriver + 526940\n10  chromedriver                        0x00000001007a9908 chromedriver + 530696\n11  chromedriver                        0x0000000100b10db4 chromedriver + 4099508\n12  chromedriver                        0x0000000100b15270 chromedriver + 4117104\n13  chromedriver                        0x0000000100b1b4fc chromedriver + 4142332\n14  chromedriver                        0x0000000100b15d70 chromedriver + 4119920\n15  chromedriver                        0x0000000100aeda44 chromedriver + 3955268\n16  chromedriver                        0x0000000100b32a18 chromedriver + 4237848\n17  chromedriver                        0x0000000100b32b94 chromedriver + 4238228\n18  chromedriver                        0x0000000100b42a5c chromedriver + 4303452\n19  libsystem_pthread.dylib             0x0000000190787fa8 _pthread_start + 148\n20  libsystem_pthread.dylib             0x0000000190782da0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:90\u001b[0m, in \u001b[0;36mWebElement.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The text of the element.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_ELEMENT_TEXT\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:403\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    401\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    402\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: chrome=117.0.5938.149)\nStacktrace:\n0   chromedriver                        0x0000000100b4ad68 chromedriver + 4337000\n1   chromedriver                        0x0000000100b42de4 chromedriver + 4304356\n2   chromedriver                        0x000000010076fa5c chromedriver + 293468\n3   chromedriver                        0x0000000100774cc8 chromedriver + 314568\n4   chromedriver                        0x00000001007768dc chromedriver + 321756\n5   chromedriver                        0x0000000100776a08 chromedriver + 322056\n6   chromedriver                        0x00000001007af3d4 chromedriver + 553940\n7   chromedriver                        0x00000001007aa200 chromedriver + 532992\n8   chromedriver                        0x00000001007ef908 chromedriver + 817416\n9   chromedriver                        0x00000001007a8a5c chromedriver + 526940\n10  chromedriver                        0x00000001007a9908 chromedriver + 530696\n11  chromedriver                        0x0000000100b10db4 chromedriver + 4099508\n12  chromedriver                        0x0000000100b15270 chromedriver + 4117104\n13  chromedriver                        0x0000000100b1b4fc chromedriver + 4142332\n14  chromedriver                        0x0000000100b15d70 chromedriver + 4119920\n15  chromedriver                        0x0000000100aeda44 chromedriver + 3955268\n16  chromedriver                        0x0000000100b32a18 chromedriver + 4237848\n17  chromedriver                        0x0000000100b32b94 chromedriver + 4238228\n18  chromedriver                        0x0000000100b42a5c chromedriver + 4303452\n19  libsystem_pthread.dylib             0x0000000190787fa8 _pthread_start + 148\n20  libsystem_pthread.dylib             0x0000000190782da0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "body.text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e39cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
